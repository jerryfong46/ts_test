# -*- coding: utf-8 -*-
"""Attrition Forecast b.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/127T6rkTMNcBrqEX_nfl-eMdrsn2MsBCr
"""

import pandas as pd
import numpy as np
from datetime import date, datetime, timedelta
from matplotlib import pyplot
from math import sqrt

from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import StandardScaler

from keras.models import Sequential
from keras.layers import LSTM, Dense, Dropout, Flatten

"""**Data Prep**

---



---


"""

#load dataset
path = '/content/'
df = pd.read_csv(path+'agent_attrition_daily.csv')
df.columns=['Date','Attrition']

#fill in nulls w/ mean
df['Attrition'] = df['Attrition'].fillna(df['Attrition'].mean())

#convert to proper datatypes, add weekday, etc.
df['Date'] = pd.to_datetime(df['Date'], format='%Y-%m-%d')
df['Weekday'] = [x.weekday() for x in df['Date']]
df['Month'] = pd.DatetimeIndex(df['Date']).month
df['Day'] = pd.DatetimeIndex(df['Date']).day

"""**Exploratory**

---



---


"""

df[['Date','Attrition']].plot(x='Date', title='Daily Attrition')

"""Evidence of attrition micro trends/seasonality within time periods. Greater attrition during: a) Fridays, b) End of the Month, c) End of Year/Start of Year"""

df[['Weekday','Attrition']].groupby('Weekday').mean().plot(title='Average Attrition by Day of Week')

df[['Month','Attrition']].groupby('Month').mean().plot(title='Average Attrition by Month')

df[['Day','Attrition']].groupby('Day').mean().plot(title='Average Attrition by Day')

"""**Modelling**

---


"""

#test for stationarity of time series/if transformations are required
x1, x2 = df['Attrition'][0:180], df['Attrition'][-180:]
print(x1.mean(), x2.mean())
print(x1.var(), x2.var())

#create baseline prediction/persistence for rmse comparison
x = df['Attrition'].values
train, test = x[0:-15], x[-15:]

history = [x for x in train]
predictions = list()

for i in range(len(test)):
  predictions.append(history[-1])
  history.append(test[i])

rmse=sqrt(mean_squared_error(test, predictions))
print(rmse)

pyplot.plot(test)
pyplot.plot(predictions)
pyplot.show()

"""**Prepare the Dataset**"""

# preparing independent and dependent features
def prepare_data(timeseries_data, n_features):
	X, y =[],[]
	for i in range(len(timeseries_data)):
		# find the end of this pattern
		end_ix = i + n_features
		# check if we are beyond the sequence
		if end_ix > len(timeseries_data)-1:
			break
		# gather input and output parts of the pattern
		seq_x, seq_y = timeseries_data[i:end_ix], timeseries_data[end_ix]
		X.append(seq_x)
		y.append(seq_y)
	return np.array(X), np.array(y)

# define input sequence
ts_df = df['Attrition']
#define params
n_steps = 7
n_epochs = 30 #keep low for testing, increase for actual training
pred_days = 10 #days lookforward

#split into testing/training
train, test = ts_df[0:-pred_days], ts_df[-pred_days:]
val_dates = df['Date'][-pred_days:]
val_attrition = df['Attrition'][-pred_days:]

# split into samples
X, y = prepare_data(train, n_steps)

#univariate
n_features = 1
X = X.reshape((X.shape[0], X.shape[1], n_features))

"""Model Training & Evaluation"""

#model params
model = Sequential()
model.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(n_steps, n_features)))
model.add(LSTM(50, activation='relu'))
model.add(Dense(1))
model.compile(optimizer='adam', loss='mse')
model.fit(X, y, epochs=n_epochs, verbose=1)

def make_prediction(x_input, temp_input):
  lst_output=[]
  i=0

  #walkforward prediction, use ouptut as input for next x inputs
  while(i<pred_days):
      
      if(len(temp_input)>n_steps): #if enough prior days of data
          x_input=np.array(temp_input[1:])
          x_input = x_input.reshape((1, n_steps, n_features))
          yhat = model.predict(x_input, verbose=0)

          temp_input.append(yhat[0][0])
          temp_input=temp_input[1:]
          lst_output.append(yhat[0][0])
          i=i+1
      else:
          x_input = x_input.values.reshape((1, n_steps, n_features))
          yhat = model.predict(x_input, verbose=0)
          temp_input.append(yhat[0][0])
          lst_output.append(yhat[0][0])
          i=i+1
  return(lst_output)

x_input = train[-n_steps:]
temp_input=list(x_input)
val_pred = make_prediction(x_input, temp_input)

pyplot.plot(val_dates,df['Attrition'][-pred_days:])
pyplot.plot(val_dates,val_pred)

rmse=sqrt(mean_squared_error(val_pred, df['Attrition'][-pred_days:]))
print(rmse)

"""Predicted Attrition for next 10 days"""

# demonstrate prediction for next 10 days
x_input = test[-n_steps:]
temp_input=list(x_input)
val_pred = make_prediction(x_input, temp_input)

#create date labels for forecasted data
start_date = pd.to_datetime('2022-03-20', format='%Y-%m-%d')
end_date = start_date + timedelta(days=10)
lst_dates = []
while start_date < end_date:
    start_date += timedelta(days=1)
    lst_dates.append(start_date)

pyplot.plot(df['Date'][-15:],ts_df[-15:]) 
pyplot.plot(lst_dates, val_pred)

"""**Key Findings/Overview**

---


> Clear trends in attrition visible on an annual/monthly/daily level - higher attrition during end of week, end of month, and end of year/start of year.


> Performance of LTSM Recurrent Neural Network displayed signicant improvements over Base/Persistence Model


> Possible future improvements: 
1. Incorporate absolute employee count (e.g. attrition as %)
2. Additional features (e.g. number of external postings for similar roles)
3. Further tuning of RNN model/evaluation of other models like traditional ARIMA models
4. Incorporate other business insights into modelling parameters











"""

# Commented out IPython magic to ensure Python compatibility.
# %%shell
# jupyter nbconvert --to html /content/attrition_daily_forecast.ipynb

